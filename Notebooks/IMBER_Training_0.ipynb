{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4500be44",
   "metadata": {},
   "source": [
    "# Processing Sentinel-3 OLCI Level 2 \n",
    "\n",
    "Sentinel-3 OLCI Level 2 dataset are obtained from Microsoft's **Planetary Computer** data repository. \n",
    "\n",
    "Dataset in this repository are saved using `STAC`, which can be accessed with Python by using `pystac` and `fsspec` modules. Dataset can be read using `numpy` and `xarray`. The `eumartools` module used to subset data to area of interest as well as applying flags to masked out unreliable data values.\n",
    "\n",
    "## Processing steps:\n",
    "\n",
    "1. Obtain dataset,\n",
    "\n",
    "    In this step, we pass the information about the area and time of interest to data server using `pystac`. It will then cataloging the suitable dataset. The path to the dataset is provided by `fsspec` module using information provided by `pystac`.\n",
    "\n",
    "2. Subset to the area of interest,\n",
    "\n",
    "    Dataset can be read using `xarray` and `numpy` module. To subset the data, first we read the dataset variables and saved it to numpy array. Area subsetting performed using `eumartools` module provided by EUMETSAT. \n",
    "\n",
    "3. Apply flags to masked out unreliable data,\n",
    "\n",
    "    In previous step, we also read suitable flags for each variables using `eumartools`. Using numpy function, the flags is then applied to masked out unreliable values from the data array\n",
    "\n",
    "4. Save subsetted and masked data to netCDF file format.\n",
    "\n",
    "    After the process, data is saved in memory as numpy n-dimensional array. The arrays are then converted back to xarray dataset and then saved in disk as netCDF data.\n",
    "\n",
    "\n",
    "## The list of modules used in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd1e11-4012-47a7-8afc-d05f63e2fe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://pccompute.westeurope.cloudapp.azure.com/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'https://pccompute.westeurope.cloudapp.azure.com/'. Verify the server is running and reachable. (JupyterHub server no longer running at /user/edwa006@brin.go.id/api/kernels. Restart the server at https://pccompute.westeurope.cloudapp.azure.com/compute/hub/spawn/edwa006@brin.go.id).)."
     ]
    }
   ],
   "source": [
    "## modules to obtain dataset from Planetary Computer\n",
    "\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import fsspec\n",
    "\n",
    "\n",
    "## modules to process the data\n",
    "\n",
    "import xarray as xr\n",
    "import eumartools\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "## modules for plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import cartopy \n",
    "import cartopy.crs as ccrs\n",
    "import colormaps as cmo\n",
    "\n",
    "\n",
    "## additional modules to display or print information in Python\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## use dask gateway\n",
    "\n",
    "# import dask_gateway\n",
    "\n",
    "# cluster = dask_gateway.GatewayCluster()\n",
    "# client = cluster.get_client()\n",
    "# cluster.scale(4)\n",
    "# print(cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8250e85",
   "metadata": {},
   "source": [
    "## Area and time of interest\n",
    "\n",
    "Location of interest is the northern portion of Jakarta administrative area, which includes Jakarta Bay as well as the Kepulauan Seribu district. Available data in the `Planetary Computer` database is from November 2017 to recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05313a71-7a84-4364-ac78-bcc0ee8a7639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datetime format used: YYYY-MM-DD. Start-time/End-time.\n",
    "\n",
    "time_of_interest = \"2019-01-01/2019-06-30\"\n",
    "\n",
    "## On 7 May 2024, processed 2017-07-01/2017-12-31 \n",
    "## On 7 May 2024, processed 2018-01-01/2018-06-30 \n",
    "## On 7 May 2024, processed 2018-07-01/2018-12-31 \n",
    "## On 8 May 2024, processed 2019-01-01/2019-06-30 \n",
    "\n",
    "# Location coordinates using decimal format.\n",
    "\n",
    "west = 106.3640\n",
    "east = 107.1060\n",
    "north = -5.1350\n",
    "south = -6.1810\n",
    "\n",
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [west, south],\n",
    "            [east, south],\n",
    "            [east, north],\n",
    "            [west, north],\n",
    "            [west, south],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "subset_box_lons = [west, west, east, east, west]\n",
    "subset_box_lats = [south, north, north, south, south]\n",
    "\n",
    "extent = [west, east, south, north]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf4cc6",
   "metadata": {},
   "source": [
    "## Data search\n",
    "\n",
    "Search suitable data based on time and area of interest. `pystac` will save the data info to a catalog and the path to the data can be accessed using `fsspec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f8751-24c5-4036-b60d-1c5b2f10f9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "collection = catalog.get_collection(\"sentinel-3-olci-wfr-l2-netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cf297-3bb0-46d3-91d4-593cb86d001b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=[\"sentinel-3-olci-wfr-l2-netcdf\"],\n",
    "    intersects=area_of_interest,\n",
    "    datetime=time_of_interest,\n",
    ")\n",
    "\n",
    "# Check how many items were returned\n",
    "items = search.item_collection()\n",
    "\n",
    "printmd(f\"For selected time and locaton of interest, there are {len(items)} items available.\\n First data is from `{items[-1].properties['datetime']}` and last data `{items[0].properties['datetime']}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541bc1d5",
   "metadata": {},
   "source": [
    "#### #4 Read and process the data\n",
    "\n",
    "Choose the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30a789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys_1 = [\n",
    "    \"chl-nn\",\n",
    "    \"tsm-nn\",\n",
    "    \"chl-oc4me\",\n",
    "]\n",
    "\n",
    "keys_2 = [\n",
    "    \"oa06-reflectance\",\n",
    "    \"oa07-reflectance\",\n",
    "    \"oa08-reflectance\",\n",
    "    \"oa09-reflectance\",\n",
    "    \"oa10-reflectance\",\n",
    "    \"oa11-reflectance\",\n",
    "    \"oa12-reflectance\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in tqdm(enumerate(items, start=0), desc='Processed', total=len(items)):\n",
    "\n",
    "# Acquire the time properties\n",
    "\n",
    "    date_string = item.properties['datetime']\n",
    "    time_object = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Subset data to area of interest\n",
    "\n",
    "    geo_fid = xr.open_dataset(fsspec.open(item.assets[\"geo-coordinates\"].href).open())\n",
    "\n",
    "    lon_i = geo_fid.longitude.data\n",
    "    lat_i = geo_fid.latitude.data\n",
    "\n",
    "    ii, jj, region_mask = eumartools.subset_image(lon_i, lat_i, subset_box_lons, subset_box_lats) \n",
    "\n",
    "    lon_ii = lon_i[min(jj):max(jj), min(ii):max(ii)]\n",
    "    lat_ii = lat_i[min(jj):max(jj), min(ii):max(ii)]\n",
    "\n",
    "    lon = xr.DataArray(lon_ii, coords=None, dims=['y', 'x'])\n",
    "    lon.attrs = {\n",
    "        'units' : 'degrees_east',\n",
    "        'unit_long' : \"Degrees East\",\n",
    "        'standard_name' : \"longitude\",\n",
    "        'long_name' : \"Longitude\",\n",
    "        'axis' : 'X'\n",
    "    }\n",
    "\n",
    "    lat = xr.DataArray(lat_ii, coords=None, dims=['y', 'x'])\n",
    "    lat.attrs = {\n",
    "        'units' : 'degrees_east',\n",
    "        'unit_long' : \"Degrees North\",\n",
    "        'standard_name' : \"latitude\",\n",
    "        'long_name' : \"Latitude\",\n",
    "        'axis' : 'Y'\n",
    "    }\n",
    "\n",
    "# Create a land mask\n",
    "\n",
    "    flag_file = fsspec.open(item.assets['wqsf'].href).open()\n",
    "\n",
    "    land_mask = eumartools.flag_mask(flag_file, 'WQSF', ['LAND','INLAND_WATER','TIDAL']) # prior to 2021, flag 'COASTLINE', is not available.\n",
    "    land_mask = land_mask.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    # land_mask[land_mask == 0.0] = np.nan\n",
    "    land_mask_da = xr.DataArray(land_mask, coords=None, dims=['y', 'x'])\n",
    "\n",
    "    land = xr.Dataset()\n",
    "\n",
    "    land['lon'] = lon\n",
    "    land['lat'] = lat\n",
    "    land['mask'] = land_mask_da\n",
    "\n",
    "    land = land.set_coords(['lon', 'lat'])\n",
    "    land = land.expand_dims(dim={\"time\":[time_object]}, axis=0)\n",
    "\n",
    "    comp = dict(zlib=True, complevel=4)\n",
    "    encoding_land = {var: comp for var in land.data_vars}\n",
    "\n",
    "    land.to_netcdf(\n",
    "        f'/home/jovyan/edskywalker/Sentinel3/data/{item.id}_LAND.nc', \n",
    "        format='NETCDF4', \n",
    "        unlimited_dims=['time'],\n",
    "        encoding=encoding_land\n",
    "        )\n",
    "\n",
    "# Flags\n",
    "\n",
    "    flag_nn = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O2', 'RWNEG_O3','RWNEG_O4', 'RWNEG_O5', 'RWNEG_O6', 'RWNEG_O7', 'RWNEG_O8','OCNN_FAIL']\n",
    "                                   )\n",
    "\n",
    "    flag_nn = flag_nn.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_nn[flag_nn == 0.0] = np.nan\n",
    "\n",
    "    flag_oc = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O2', 'RWNEG_O3','RWNEG_O4', 'RWNEG_O5', 'RWNEG_O6', 'RWNEG_O7', 'RWNEG_O8','OC4ME_FAIL']\n",
    "                                   )\n",
    "\n",
    "    flag_oc = flag_oc.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_oc[flag_oc == 0.0] = np.nan\n",
    "\n",
    "    flag_re_06 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O6']\n",
    "                                   )\n",
    "\n",
    "    flag_re_06 = flag_re_06.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_06[flag_re_06 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_07 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O7']\n",
    "                                   )\n",
    "\n",
    "    flag_re_07 = flag_re_07.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_07[flag_re_07 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_08 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O8']\n",
    "                                   )\n",
    "\n",
    "    flag_re_08 = flag_re_08.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_08[flag_re_08 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_09 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O9']\n",
    "                                   )\n",
    "\n",
    "    flag_re_09 = flag_re_09.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_09[flag_re_09 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_10 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O10']\n",
    "                                   )\n",
    "\n",
    "    flag_re_10 = flag_re_10.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_10[flag_re_10 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_11 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O11']\n",
    "                                   )\n",
    "\n",
    "    flag_re_11 = flag_re_11.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_11[flag_re_11 == 0.0] = np.nan\n",
    "\n",
    "    flag_re_12 = eumartools.flag_mask(flag_file, 'WQSF',\n",
    "                                   ['LAND', 'CLOUD', 'CLOUD_AMBIGUOUS', 'CLOUD_MARGIN', 'INVALID', 'COSMETIC', 'SATURATED', 'SUSPECT', 'HISOLZEN', 'HIGHGLINT', 'SNOW_ICE', 'AC_FAIL','WHITECAPS', 'ADJAC', 'RWNEG_O12']\n",
    "                                   )\n",
    "\n",
    "    flag_re_12 = flag_re_12.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    flag_re_12[flag_re_12 == 0.0] = np.nan\n",
    "\n",
    "    ## BIOGEOCHEMICAL PROPERTIES\n",
    "\n",
    "    biog = [xr.open_dataset(fsspec.open(item.assets[k].href).open()) for k in keys_1]\n",
    "    ds_biog = xr.combine_by_coords(biog, join=\"exact\", combine_attrs=\"drop_conflicts\")\n",
    "\n",
    "    chl_nn = np.array(ds_biog['CHL_NN'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    chl_nn[flag_nn == 1] = np.nan\n",
    "\n",
    "    tsm_nn = np.array(ds_biog['TSM_NN'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    tsm_nn[flag_nn == 1] = np.nan\n",
    "\n",
    "    chl_oc = np.array(ds_biog['CHL_OC4ME'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    chl_oc[flag_oc == 1] = np.nan\n",
    "\n",
    "    chl_nn_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    chl_nn_da.attrs = ds_biog.CHL_NN.attrs\n",
    "    chl_oc_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    chl_oc_da.attrs = ds_biog.CHL_OC4ME.attrs\n",
    "    tsm_nn_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    tsm_nn_da.attrs = ds_biog.TSM_NN.attrs\n",
    "\n",
    "    # Create xarray dataset and save to netCDF format.\n",
    "\n",
    "    chl_ds = xr.Dataset()\n",
    "\n",
    "    chl_ds['lon'] = lon\n",
    "    chl_ds['lat'] = lat\n",
    "    chl_ds['chl_nn'] = chl_nn_da\n",
    "    chl_ds['chl_oc'] = chl_oc_da\n",
    "    chl_ds['tsm_nn'] = tsm_nn_da\n",
    "\n",
    "    chl_ds = chl_ds.set_coords(['lon', 'lat'])\n",
    "    chl_ds = chl_ds.expand_dims(dim={\"time\":[time_object]}, axis=0)\n",
    "\n",
    "    comp = dict(zlib=True, complevel=4, _FillValue=-9999.)\n",
    "    encoding = {var: comp for var in chl_ds.data_vars}\n",
    "\n",
    "    chl_ds.to_netcdf(\n",
    "        f'/home/jovyan/edskywalker/Sentinel3/data/{item.id}_BIOGEOCHEMISTRY.nc', \n",
    "        format='NETCDF4', \n",
    "        unlimited_dims=['time'],\n",
    "        encoding=encoding\n",
    "        )\n",
    "\n",
    "## REFLECTANCE\n",
    "\n",
    "    refl = [xr.open_dataset(fsspec.open(item.assets[k].href).open()) for k in keys_2]\n",
    "    ds_refl = xr.combine_by_coords(refl, join=\"exact\", combine_attrs=\"drop_conflicts\")\n",
    "\n",
    "    Oa06 = np.array(ds_refl['Oa06_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa06[flag_re_06 == 1] = np.nan\n",
    "    Oa07 = np.array(ds_refl['Oa07_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa07[flag_re_07 == 1] = np.nan\n",
    "    Oa08 = np.array(ds_refl['Oa08_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa08[flag_re_08 == 1] = np.nan\n",
    "    Oa09 = np.array(ds_refl['Oa09_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa09[flag_re_09 == 1] = np.nan\n",
    "    Oa10 = np.array(ds_refl['Oa10_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa10[flag_re_10 == 1] = np.nan\n",
    "    Oa11 = np.array(ds_refl['Oa11_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa11[flag_re_11 == 1] = np.nan\n",
    "    Oa12 = np.array(ds_refl['Oa12_reflectance'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    Oa12[flag_re_12 == 1] = np.nan\n",
    "\n",
    "    ds_refl.close()\n",
    "    del refl\n",
    "    \n",
    "    Oa06_da = xr.DataArray(Oa06, coords=None, dims=['y', 'x'])\n",
    "    Oa06_da.attrs = ds_refl.Oa06_reflectance.attrs\n",
    "\n",
    "    Oa07_da = xr.DataArray(Oa07, coords=None, dims=['y', 'x'])\n",
    "    Oa07_da.attrs = ds_refl.Oa07_reflectance.attrs\n",
    "\n",
    "    Oa08_da = xr.DataArray(Oa08, coords=None, dims=['y', 'x'])\n",
    "    Oa08_da.attrs = ds_refl.Oa08_reflectance.attrs\n",
    "\n",
    "    Oa09_da = xr.DataArray(Oa09, coords=None, dims=['y', 'x'])\n",
    "    Oa09_da.attrs = ds_refl.Oa09_reflectance.attrs\n",
    "\n",
    "    Oa10_da = xr.DataArray(Oa10, coords=None, dims=['y', 'x'])\n",
    "    Oa10_da.attrs = ds_refl.Oa10_reflectance.attrs\n",
    "\n",
    "    Oa11_da = xr.DataArray(Oa11, coords=None, dims=['y', 'x'])\n",
    "    Oa11_da.attrs = ds_refl.Oa11_reflectance.attrs\n",
    "\n",
    "    Oa12_da = xr.DataArray(Oa12, coords=None, dims=['y', 'x'])\n",
    "    Oa12_da.attrs = ds_refl.Oa12_reflectance.attrs\n",
    "\n",
    "    ref_ds = xr.Dataset()\n",
    "\n",
    "    ref_ds['lon'] = lon\n",
    "    ref_ds['lat'] = lat\n",
    "\n",
    "    ref_ds['Oa06'] = Oa06_da\n",
    "    ref_ds['Oa07'] = Oa07_da\n",
    "    ref_ds['Oa08'] = Oa08_da\n",
    "    ref_ds['Oa09'] = Oa09_da\n",
    "    ref_ds['Oa10'] = Oa10_da\n",
    "    ref_ds['Oa11'] = Oa11_da\n",
    "    ref_ds['Oa12'] = Oa12_da\n",
    "\n",
    "    ref_ds = ref_ds.set_coords(['lon', 'lat'])\n",
    "\n",
    "    ref_ds = ref_ds.expand_dims(dim={\"time\":[time_object]}, axis=0)\n",
    "    \n",
    "    comp = dict(zlib=True, _FillValue=-99999.0, complevel=4)\n",
    "    encoding = {var: comp for var in ref_ds.data_vars}\n",
    "\n",
    "    ref_ds.to_netcdf(\n",
    "        f'/home/jovyan/edskywalker/Sentinel3/data/{item.id}_REFLECTANCES.nc', \n",
    "        format='NETCDF4', \n",
    "        unlimited_dims=['time'],\n",
    "        encoding=encoding\n",
    "        )\n",
    "    \n",
    "    ref_ds.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca14441",
   "metadata": {},
   "source": [
    "Plot to examine the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_plot = xr.open_dataset(f'/home/jovyan/edskywalker/Sentinel3/data/{items[31].id}_BIOGEOCHEMISTRY.nc')\n",
    "\n",
    "for_plot['chl_nn'] = 10 ** for_plot['chl_nn'] \n",
    "for_plot['tsm_nn'] = 10 ** for_plot['tsm_nn'] \n",
    "\n",
    "fig, ax = plt.subplots(figsize=[13,6], ncols=2, layout='constrained', subplot_kw=dict(projection=ccrs.Mercator()))\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_extent(extent)\n",
    "    ax[i].add_feature(cartopy.feature.LAND.with_scale('10m'), facecolor = 'beige', edgecolor='black', zorder = 1)\n",
    "\n",
    "    ini = ax[i].gridlines(draw_labels = True, alpha=0.5)\n",
    "    ini.top_labels = False\n",
    "    ini.right_labels = False\n",
    "\n",
    "for_plot.chl_nn.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[0], norm=colors.LogNorm(0.01,100), cmap=cmo.algae, zorder=0, transform=ccrs.PlateCarree())\n",
    "for_plot.tsm_nn.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[1], norm=colors.LogNorm(0.01,100), cmap=cmo.matter, zorder=0, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de766f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ds = xr.open_dataset(f'/home/jovyan/edskywalker/Sentinel3/data/{items[31].id}_REFLECTANCES.nc')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[20,6], ncols=3, layout='constrained', subplot_kw=dict(projection=ccrs.Mercator()))\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_extent(extent)\n",
    "    ax[i].add_feature(cartopy.feature.LAND.with_scale('10m'), facecolor = 'beige', edgecolor='black', zorder = 1)\n",
    "\n",
    "    ini = ax[i].gridlines(draw_labels = True, alpha=0.5)\n",
    "    ini.top_labels = False\n",
    "    ini.right_labels = False\n",
    "\n",
    "ref_ds.Oa08.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[0], norm=colors.Normalize(0, 0.2), cmap=cmo.tropical, zorder=0, transform=ccrs.PlateCarree())\n",
    "ref_ds.Oa06.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[1], norm=colors.Normalize(0, 0.2), cmap=cmo.tropical, zorder=0, transform=ccrs.PlateCarree())\n",
    "ref_ds.Oa12.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[2], norm=colors.Normalize(0, 0.2), cmap=cmo.tropical, zorder=0, transform=ccrs.PlateCarree())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72653d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:testEnv]",
   "language": "python",
   "name": "conda-env-testEnv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
