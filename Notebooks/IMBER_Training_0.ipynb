{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4500be44",
   "metadata": {},
   "source": [
    "# Processing Sentinel-3 OLCI Level 2 \n",
    "\n",
    "Sentinel-3 OLCI Level 2 dataset are obtained from Microsoft's **Planetary Computer** data repository. \n",
    "\n",
    "Dataset in this repository are saved using `STAC`, which can be accessed with Python by using `pystac` and `fsspec` modules. Dataset can be read using `numpy` and `xarray`. The `eumartools` module used to subset data to area of interest as well as applying flags to masked out unreliable data values.\n",
    "\n",
    "## Processing steps:\n",
    "\n",
    "1. Obtain dataset,\n",
    "\n",
    "    In this step, we pass the information about the area and time of interest to data server using `pystac`. It will then cataloging the suitable dataset. The path to the dataset is provided by `fsspec` module using information provided by `pystac`.\n",
    "\n",
    "2. Subset to the area of interest,\n",
    "\n",
    "    Dataset can be read using `xarray` and `numpy` module. To subset the data, first we read the dataset variables and saved it to numpy array. Area subsetting performed using `eumartools` module provided by EUMETSAT. \n",
    "\n",
    "3. Apply flags to masked out unreliable data,\n",
    "\n",
    "    In previous step, we also read suitable flags for each variables using `eumartools`. Using numpy function, the flags is then applied to masked out unreliable values from the data array\n",
    "\n",
    "4. Save subsetted and masked data to netCDF file format.\n",
    "\n",
    "    After the process, data is saved in memory as numpy n-dimensional array. The arrays are then converted back to xarray dataset and then saved in disk as netCDF data.\n",
    "\n",
    "\n",
    "## The list of modules used in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd1e11-4012-47a7-8afc-d05f63e2fe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modules to obtain dataset from Planetary Computer\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import fsspec\n",
    "\n",
    "# modules to process the data\n",
    "import xarray as xr\n",
    "import eumartools\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# modules for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import cartopy \n",
    "import cartopy.crs as ccrs\n",
    "import colormaps as cmo\n",
    "\n",
    "# additional modules to display or print information in Python\n",
    "from IPython.display import display, Markdown\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8250e85",
   "metadata": {},
   "source": [
    "## Area and time of interest\n",
    "\n",
    "Location of interest is the northern portion of Jakarta administrative area, which includes Jakarta Bay as well as the Kepulauan Seribu district. Available data in the `Planetary Computer` database is from November 2017 to recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05313a71-7a84-4364-ac78-bcc0ee8a7639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datetime format used: YYYY-MM-DD. Start-time/End-time.\n",
    "\n",
    "time_of_interest = \"2023-03-31/2023-04-07\"\n",
    "\n",
    "# Location coordinates using decimal format.\n",
    "\n",
    "west = 106.3640\n",
    "east = 107.1060\n",
    "north = -5.1350\n",
    "south = -6.1810\n",
    "\n",
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [west, south],\n",
    "            [east, south],\n",
    "            [east, north],\n",
    "            [west, north],\n",
    "            [west, south],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "subset_box_lons = [west, west, east, east, west]\n",
    "subset_box_lats = [south, north, north, south, south]\n",
    "\n",
    "extent = [west, east, south, north]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf4cc6",
   "metadata": {},
   "source": [
    "## Data search\n",
    "\n",
    "Search suitable data based on time and area of interest. `pystac` will save the data info to a catalog and the path to the data can be accessed using `fsspec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f8751-24c5-4036-b60d-1c5b2f10f9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "collection = catalog.get_collection(\"sentinel-3-olci-wfr-l2-netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cf297-3bb0-46d3-91d4-593cb86d001b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=[\"sentinel-3-olci-wfr-l2-netcdf\"],\n",
    "    intersects=area_of_interest,\n",
    "    datetime=time_of_interest,\n",
    ")\n",
    "\n",
    "# Check how many items were returned\n",
    "items = search.item_collection()\n",
    "\n",
    "printmd(f\"For selected time and locaton of interest, there are {len(items)} items available.\\n First data is from `{items[-1].properties['datetime']}` and last data `{items[0].properties['datetime']}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541bc1d5",
   "metadata": {},
   "source": [
    "#### #4 Read and process the data\n",
    "\n",
    "Choose the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30a789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys_1 = [\n",
    "    \"chl-nn\",\n",
    "    \"tsm-nn\",\n",
    "    \"chl-oc4me\",\n",
    "]\n",
    "\n",
    "keys_2 = [\n",
    "    \"oa06-reflectance\",\n",
    "    \"oa07-reflectance\",\n",
    "    \"oa08-reflectance\",\n",
    "    \"oa09-reflectance\",\n",
    "    \"oa10-reflectance\",\n",
    "    \"oa11-reflectance\",\n",
    "    \"oa12-reflectance\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in tqdm(enumerate(items, start=0), desc='Processed', total=len(items)):\n",
    "\n",
    "# Acquire the time properties\n",
    "\n",
    "    date_string = item.properties['datetime']\n",
    "    time_object = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Subset data to area of interest\n",
    "\n",
    "    geo_fid = xr.open_dataset(fsspec.open(item.assets[\"geo-coordinates\"].href).open())\n",
    "\n",
    "    lon_i = geo_fid.longitude.data\n",
    "    lat_i = geo_fid.latitude.data\n",
    "\n",
    "    ii, jj, region_mask = eumartools.subset_image(lon_i, lat_i, subset_box_lons, subset_box_lats) \n",
    "\n",
    "    lon_ii = lon_i[min(jj):max(jj), min(ii):max(ii)]\n",
    "    lat_ii = lat_i[min(jj):max(jj), min(ii):max(ii)]\n",
    "\n",
    "    lon = xr.DataArray(lon_ii, coords=None, dims=['y', 'x'])\n",
    "    lon.attrs = {\n",
    "        'units' : 'degrees_east',\n",
    "        'unit_long' : \"Degrees East\",\n",
    "        'standard_name' : \"longitude\",\n",
    "        'long_name' : \"Longitude\",\n",
    "        'axis' : 'X'\n",
    "    }\n",
    "\n",
    "    lat = xr.DataArray(lat_ii, coords=None, dims=['y', 'x'])\n",
    "    lat.attrs = {\n",
    "        'units' : 'degrees_east',\n",
    "        'unit_long' : \"Degrees North\",\n",
    "        'standard_name' : \"latitude\",\n",
    "        'long_name' : \"Latitude\",\n",
    "        'axis' : 'Y'\n",
    "    }\n",
    "\n",
    "# Create a land mask\n",
    "\n",
    "    flag_file = fsspec.open(item.assets['wqsf'].href).open()\n",
    "\n",
    "    land_mask = eumartools.flag_mask(flag_file, 'WQSF', ['LAND','INLAND_WATER','COASTLINE','TIDAL'])\n",
    "    land_mask = land_mask.astype(float)[min(jj):max(jj), min(ii):max(ii)]\n",
    "    # land_mask[land_mask == 0.0] = np.nan\n",
    "    land_mask_da = xr.DataArray(land_mask, coords=None, dims=['y', 'x'])\n",
    "\n",
    "    land = xr.Dataset()\n",
    "\n",
    "    land['lon'] = lon\n",
    "    land['lat'] = lat\n",
    "    land['mask'] = land_mask_da\n",
    "\n",
    "    land = land.set_coords(['lon', 'lat'])\n",
    "    land = land.expand_dims(dim={\"time\":[time_object]}, axis=0)\n",
    "\n",
    "    comp = dict(zlib=True, complevel=4)\n",
    "    encoding_land = {var: comp for var in land.data_vars}\n",
    "\n",
    "    land.to_netcdf(\n",
    "        f'/home/jovyan/edskywalker/Sentinel3/data/{item.id}_LAND.nc', \n",
    "        format='NETCDF4', \n",
    "        unlimited_dims=['time'],\n",
    "        encoding=encoding_land\n",
    "        )\n",
    "\n",
    "#    fig, ax = plt.subplots(figsize=[8,6], layout='constrained', subplot_kw=dict(projection=ccrs.Mercator()))\n",
    "#\n",
    "#    ini = ax.gridlines(draw_labels = True, alpha=0.5)\n",
    "#    ini.top_labels = False\n",
    "#    ini.right_labels = False\n",
    "#\n",
    "#    land.mask.plot(x='lon', y='lat', ax=ax, transform=ccrs.PlateCarree())\n",
    "#\n",
    "#    fig.savefig(f'/home/jovyan/edskywalker/Sentinel3/images/{item.id}_LAND.png', dpi=300, bbox_inches='tight', pad_inches=0.05)\n",
    "#    plt.close(fig)    # close the figure window\n",
    "\n",
    "    ## BIOGEOCHEMICAL PROPERTIES\n",
    "\n",
    "    biog = [xr.open_dataset(fsspec.open(items.assets[k].href).open()) for k in keys_1]\n",
    "    ds_biog = xr.combine_by_coords(biog, join=\"exact\", combine_attrs=\"drop_conflicts\")\n",
    "\n",
    "    chl_nn = np.array(ds_biog['CHL_NN'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    chl_nn[flag_nn == 1] = np.nan\n",
    "\n",
    "    tsm_nn = np.array(ds_biog['TSM_NN'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    tsm_nn[flag_nn == 1] = np.nan\n",
    "\n",
    "    chl_oc = np.array(ds_biog['CHL_OC4ME'].data[min(jj):max(jj), min(ii):max(ii)])\n",
    "    chl_oc[flag_oc == 1] = np.nan\n",
    "\n",
    "    chl_nn_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    chl_nn_da.attrs = ds_biog.CHL_NN.attrs\n",
    "    chl_oc_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    chl_oc_da.attrs = ds_biog.CHL_OC4ME.attrs\n",
    "    tsm_nn_da = xr.DataArray(chl_nn, coords=None, dims=['y', 'x'])\n",
    "    tsm_nn_da.attrs = ds_biog.TSM_NN.attrs\n",
    "\n",
    "    # Create xarray dataset and save to netCDF format.\n",
    "\n",
    "    chl_ds = xr.Dataset()\n",
    "\n",
    "    chl_ds['lon'] = lon\n",
    "    chl_ds['lat'] = lat\n",
    "    chl_ds['chl_nn'] = chl_nn_da\n",
    "    chl_ds['chl_oc'] = chl_oc_da\n",
    "    chl_ds['tsm_nn'] = tsm_nn_da\n",
    "\n",
    "    chl_ds = chl_ds.set_coords(['lon', 'lat'])\n",
    "    chl_ds = chl_ds.expand_dims(dim={\"time\":[time_object]}, axis=0)\n",
    "\n",
    "    comp = dict(zlib=True, complevel=4, _FillValue=-9999.)\n",
    "    encoding = {var: comp for var in chl_ds.data_vars}\n",
    "\n",
    "    chl_ds.to_netcdf(\n",
    "        f'/home/jovyan/edskywalker/Sentinel3/data/{item.id}_BIOGEOCHEMISTRY.nc', \n",
    "        format='NETCDF4', \n",
    "        unlimited_dims=['time'],\n",
    "        encoding=encoding\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5701d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f8af731",
   "metadata": {},
   "source": [
    "Apply mask to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28b454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca14441",
   "metadata": {},
   "source": [
    "Plot to examine the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_plot = chl_ds\n",
    "for_plot['chl_nn'] = 10 ** for_plot['chl_nn'] \n",
    "for_plot['tsm_nn'] = 10 ** for_plot['tsm_nn'] \n",
    "\n",
    "fig, ax = plt.subplots(figsize=[13,6], ncols=2, layout='constrained', subplot_kw=dict(projection=ccrs.Mercator()))\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_extent(extent)\n",
    "    ax[i].add_feature(cartopy.feature.LAND.with_scale('10m'), facecolor = 'beige', edgecolor='black', zorder = 1)\n",
    "\n",
    "    ini = ax[i].gridlines(draw_labels = True, alpha=0.5)\n",
    "    ini.top_labels = False\n",
    "    ini.right_labels = False\n",
    "\n",
    "for_plot.chl_nn.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[0], norm=colors.LogNorm(0.01,100), cmap=cmo.algae, zorder=0, transform=ccrs.PlateCarree())\n",
    "for_plot.tsm_nn.isel(time=0).plot.pcolormesh(x='lon', y='lat', ax=ax[1], norm=colors.LogNorm(0.01,100), cmap=cmo.matter, zorder=0, transform=ccrs.PlateCarree())\n",
    "\n",
    "fig.savefig(f'/home/jovyan/edskywalker/Sentinel3/images/{items[0].id}_CHL_TSM.png', dpi=300, bbox_inches='tight', pad_inches=0.05)   # save the figure to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de766f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:testEnv]",
   "language": "python",
   "name": "conda-env-testEnv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
